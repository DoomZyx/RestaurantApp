import { FunctionCallService } from "../services/FunctionCallService.js";

/** Timestamp ISO pour logs barge-in (diagnostic temps r√©el) */
const ts = () => new Date().toISOString();

/** D√©lai (ms) sans envoi d'audio apr√®s response.created pour laisser arriver speech_started. */
const AUDIO_HOLD_MS = 500;
/** D√©lai (ms) avant d'envoyer chaque chunk audio vers Twilio. Mettre √† 50 pour tester si r√©ponses plus lentes am√©liorent le barge-in. 0 = pas de d√©lai. */
const STREAM_DELAY_MS = 0;

/**
 * Gestionnaire des messages OpenAI
 * Traite tous les √©v√©nements du WebSocket OpenAI :
 * - Session (configuration)
 * - R√©ponses (audio, transcription, texte)
 * - Interactions utilisateur (speech, transcription)
 * - Function calls (disponibilit√©s, rendez-vous)
 */
export class OpenAIHandler {
  constructor(streamSid, connection, callLogger, openAiWs) {
    this.streamSid = streamSid;
    this.connection = connection;
    this.callLogger = callLogger;
    this.openAiWs = openAiWs;
    this.transcription = `Appel d√©marr√© - StreamSid: ${streamSid}\n`;
    this.isAssistantSpeaking = false;
    this.currentResponseId = null;
    /** True apr√®s une interruption (barge-in) : on ne renvoie plus l'audio vers Twilio jusqu'√† response.done/cancelled */
    this.isInterrupted = false;
    this.shouldCancel = false;
    this._audioDeltaLogged = false;
    /** True apr√®s input_audio_buffer.committed : le serveur va envoyer response.created */
    this.awaitingResponse = false;
    /** True apr√®s speech_started (avant response.created) ; false apr√®s speech_stopped. Annuler la r√©ponse seulement si encore true √† response.created */
    this.userStillSpeaking = false;
    this.currentResponseText = "";
    this.initialGreetingSent = false;
    this._suppressLogged = false;
    /** Timestamp jusqu'auquel on ne transmet pas l'audio (fen√™tre barge-in juste apr√®s response.created) */
    this._audioHoldUntil = 0;
  }

  /** Met √† jour le streamSid (appel√© au premier event "start" Twilio) */
  setStreamSid(streamSid) {
    this.streamSid = streamSid;
  }

  /**
   * Point d'entr√©e pour tous les messages OpenAI
   * @param {Object} data - Message re√ßu d'OpenAI
   */
  handleMessage(data) {
    switch (data.type) {
      case "session.updated":
        this.handleSessionUpdated(data);
        break;
      case "response.created":
        this.handleResponseCreated(data);
        break;
      case "response.output_item.added":
      case "response.output_item.created":
        this.handleOutputItemAdded(data);
        break;
      case "response.audio.delta":
        this.handleAudioDelta(data);
        break;
      case "response.done":
        this.handleResponseCompleted(data);
        break;
      case "response.cancelled":
        this.handleResponseCancelled();
        break;
      case "response.audio_transcript.delta":
        this.handleAudioTranscriptDelta(data);
        break;
      case "response.text.delta":
        this.handleTextDelta(data);
        break;
      case "response.text.completed":
        this.handleTextCompleted();
        break;
      case "input_audio_buffer.committed":
        this.awaitingResponse = true;
        this.handleInputCommitted();
        break;
      case "input_audio_buffer.speech_stopped":
        this.userStillSpeaking = false;
        break;
      case "input_audio_buffer.speech_started":
        this.handleUserSpeechStarted();
        break;
      case "conversation.item.input_audio_transcription.completed":
        this.handleUserTranscription(data);
        break;
      case "response.function_call_arguments.delta":
        this.handleFunctionCallDelta(data);
        break;
      case "response.function_call_arguments.done":
        this.handleFunctionCallCompleted(data);
        break;
      case "error":
        this.handleError(data);
        break;
      default:
        this.callLogger.debug(this.streamSid, `Message OpenAI: ${data.type}`, {
          messageType: data.type,
          hasTranscript: !!data.transcript,
        });
    }
  }

  // ==========================================
  // GESTION DE SESSION
  // ==========================================

  /**
   * Tour utilisateur termin√© (input_audio_buffer.committed).
   * Avec create_response: false, on envoie response.create nous-m√™mes pour d√©clencher la r√©ponse.
   */
  handleInputCommitted() {
    if (this.openAiWs && this.openAiWs.readyState === 1) {
      this.openAiWs.send(JSON.stringify({ type: "response.create" }));
      this.callLogger.debug(this.streamSid, "response.create envoye (tour utilisateur committe)");
    }
  }

  /**
   * G√®re la mise √† jour de session (d√©clenche la salutation initiale)
   */
  handleSessionUpdated(data) {
    if (!this.initialGreetingSent && this.openAiWs && this.openAiWs.readyState === 1) {
      this.initialGreetingSent = true;
      
      this.callLogger.info(this.streamSid, "üé§ Envoi de la salutation automatique");
      
      // Forcer une r√©ponse de l'assistant sans attendre l'utilisateur
      this.openAiWs.send(JSON.stringify({
        type: "response.create"
      }));
    }
  }

  // ==========================================
  // GESTION DES R√âPONSES ASSISTANT
  // ==========================================

  /**
   * D√©but d'une nouvelle r√©ponse de l'assistant.
   * Si shouldCancel est vrai (speech_started √©tait arriv√© avant), on cancel imm√©diatement avant tout stream.
   * Sinon, on retient l'audio 300 ms pour laisser le temps au speech_started d'arriver (barge-in).
   * Limitation : l'audio deja envoye a Twilio ne peut pas etre annule (buffer cote Twilio).
   */
  handleResponseCreated(data) {
    this.currentResponseId = data.response.id;
    this.isAssistantSpeaking = true;
  
    if (this.shouldCancel) {
      this.openAiWs.send(JSON.stringify({
        type: "response.cancel",
        response_id: this.currentResponseId
      }));
  
      this.shouldCancel = false;
      this.isAssistantSpeaking = false;
      this.currentResponseId = null;
    }
  }

  /**
   * Fin de la r√©ponse de l'assistant
   */
  async handleResponseCompleted(data) {
    const remainingText = this.currentResponseText.trim();
    
    this.callLogger.extractionCompleted(this.streamSid, {
      output_text: remainingText ? remainingText.substring(0, 100) + "..." : "D√©j√† stream√©",
    });

    const doneId = data.response?.id ?? this.currentResponseId;
    console.log(ts(), "[OPENAI] response.done", doneId);
    this.isAssistantSpeaking = false;
    this.isInterrupted = false;
    this.currentResponseId = null;
    this.shouldCancel = false;
    this.awaitingResponse = false;
    this.userStillSpeaking = false;
    this._audioDeltaLogged = false;
    this._suppressLogged = false;
    this.currentResponseText = "";
  }

  // ==========================================
  // GESTION AUDIO
  // ==========================================

  /**
   * R√©ception d'audio delta depuis OpenAI
   */
  async handleAudioDelta(data) {
    if (this.isInterrupted) {
      if (!this._suppressLogged) {
        this._suppressLogged = true;
        console.log(ts(), "[TWILIO] audio suppressed (barge-in)");
      }
      return;
    }
    if (this._audioHoldUntil && Date.now() < this._audioHoldUntil) {
      return;
    }
    this._audioHoldUntil = 0;
    this._suppressLogged = false;
    if (data.delta && this.streamSid) {
      if (STREAM_DELAY_MS > 0) {
        await new Promise((r) => setTimeout(r, STREAM_DELAY_MS));
      }
      if (this.isInterrupted) return;
      if (!this._audioDeltaLogged) {
        this._audioDeltaLogged = true;
        console.log(ts(), "[OPENAI] response.audio.delta (streaming)");
      }
      const audioDelta = {
        event: "media",
        streamSid: this.streamSid,
        media: {
          payload: Buffer.from(data.delta, "base64").toString("base64"),
        },
      };
      this.connection.send(JSON.stringify(audioDelta));
    }
  }

  // ==========================================
  // GESTION TRANSCRIPTION
  // ==========================================

  /**
   * R√©ception d'un delta de transcription audio (assistant)
   */
  async handleAudioTranscriptDelta(data) {
    if (data.delta) {
      this.currentResponseText += data.delta;
    }
  }

  /**
   * R√©ception de transcription utilisateur
   */
  handleUserTranscription(data) {
    if (data.transcript) {
      this.transcription += `\nClient: ${data.transcript}`;
      this.callLogger.info(
        this.streamSid,
        "Transcription client re√ßue d'OpenAI",
        {
          transcript: data.transcript.substring(0, 50) + "...",
        }
      );
      
      // Avec server_vad activ√©, OpenAI d√©clenche automatiquement une r√©ponse
    }
  }

  /**
   * R√©ception de delta de texte (mode text, non audio)
   */
  handleTextDelta(data) {
    if (!this.isAssistantSpeaking) {
      this.transcription += "\nAssistant: ";
      this.isAssistantSpeaking = true;
    }
    this.transcription += data.delta;
  }

  /**
   * Fin de texte
   */
  handleTextCompleted() {
    this.isAssistantSpeaking = false;
    this.transcription += "\n";
  }

  // ==========================================
  // GESTION INTERRUPTION
  // ==========================================

  /**
   * Item de conversation ajout√© (fallback pour item_id si output_item n'a pas la bonne structure)
   */
  handleConversationItemAdded(data) {
    if (!this.isAssistantSpeaking) return;
    const item = data.item ?? data;
    const itemId = item?.id ?? item?.item_id;
    if (itemId && (item?.role === "assistant" || item?.type === "message")) {
      this.currentOutputItemId = itemId;
      this.callLogger.debug(this.streamSid, "conversation.item id capture (assistant)", { itemId });
    }
  }

  /**
   * Item de sortie ajout√© (pour truncate sur interruption)
   * Structure possible: data.item.id, data.item_id, data.output_item.id
   */
  handleOutputItemAdded(data) {
    const itemId = data.item?.id ?? data.output_item?.id ?? data.item_id ?? data.item?.item_id;
    if (itemId) {
      this.currentOutputItemId = itemId;
      this.callLogger.debug(this.streamSid, "output_item id capture", { itemId });
    } else {
      this.callLogger.debug(this.streamSid, "output_item structure (item_id manquant)", {
        keys: Object.keys(data),
        item: data.item ? JSON.stringify(data.item).substring(0, 200) : null,
      });
    }
  }

  /**
   * Barge-in : l'utilisateur commence √† parler.
   * Doc: stopper lecture imm√©diatement, envoyer response.cancel, puis conversation.item.truncate.
   */
  handleUserSpeechStarted() {
    console.log(
      ts(),
      "[VAD] speech_started",
      "isAssistantSpeaking=" + this.isAssistantSpeaking,
      "currentResponseId=" + (this.currentResponseId || "null")
    );
  
    if (!this.openAiWs || this.openAiWs.readyState !== 1) return;
  
    // Cas 1 : le bot parle ‚Üí interruption imm√©diate
    if (this.isAssistantSpeaking && this.currentResponseId) {
      const responseId = this.currentResponseId;
  
      this.isInterrupted = true;
      this.isAssistantSpeaking = false;
      this.currentResponseId = null;
  
      this.openAiWs.send(JSON.stringify({
        type: "response.cancel",
        response_id: responseId
      }));
  
      console.log(ts(), "[OPENAI] response.cancel envoy√©", responseId);
      return;
    }
  
    // Cas 2 : r√©ponse pas encore cr√©√©e ‚Üí cancel diff√©r√©
    this.shouldCancel = true;
  }

  /**
   * R√©ponse annul√©e (apr√®s notre response.cancel).
   * R√©initialiser l'√©tat pour la prochaine r√©ponse.
   */
  handleResponseCancelled() {
    console.log(ts(), "[OPENAI] response.cancelled");
    this.isAssistantSpeaking = false;
    this.currentResponseId = null;
    this.isInterrupted = false;
    this.shouldCancel = false;
    this.awaitingResponse = false;
    this.userStillSpeaking = false;
    this._audioDeltaLogged = false;
    this._audioHoldUntil = 0;
  }

  // ==========================================
  // GESTION FUNCTION CALLS
  // ==========================================

  /**
   * R√©ception de delta d'arguments de function call
   */
  async handleFunctionCallDelta(data) {
    this.callLogger.debug(this.streamSid, "Function call delta received", {
      name: data.name,
      arguments: data.arguments,
    });
  }

  /**
   * Function call compl√©t√© - Ex√©cuter l'appel
   */
  async handleFunctionCallCompleted(data) {
    try {
      this.callLogger.info(this.streamSid, "Function call completed", {
        name: data.name,
        arguments: data.arguments,
      });

      const functionName = data.name;
      const args = JSON.parse(data.arguments || "{}");

      let result;

      switch (functionName) {
        case "check_availability":
          result = await FunctionCallService.checkAvailability(args.date);
          break;
        case "create_appointment":
          result = await FunctionCallService.createAppointment(args);
          break;
        default:
          result = { error: `Fonction inconnue: ${functionName}` };
      }

      // Envoyer le r√©sultat √† OpenAI (openAiWs, pas connection Twilio)
      if (this.openAiWs && this.openAiWs.readyState === 1) {
        this.openAiWs.send(
          JSON.stringify({
            type: "conversation.item.create",
            item: {
              type: "function_call_output",
              call_id: data.call_id,
              output: JSON.stringify(result),
            },
          })
        );
      }
    } catch (error) {
      this.callLogger.error(this.streamSid, error, {
        source: "OpenAIHandler.js",
        context: "function_call_execution",
      });
    }
  }

  // ==========================================
  // GESTION ERREURS
  // ==========================================

  /**
   * G√®re les erreurs OpenAI
   */
  handleError(data) {
    const code = data.error?.code;
    if (code === "response_cancel_not_active") {
      this.callLogger.debug(this.streamSid, "response.cancel ignor√© (r√©ponse d√©j√† termin√©e)", { code });
      this.isInterrupted = false;
      this.isAssistantSpeaking = false;
      this.currentResponseId = null;
      this._suppressLogged = false;
      this._audioHoldUntil = 0;
      return;
    }
    this.callLogger.error(this.streamSid, new Error(`OpenAI API: ${data.error?.message || 'Unknown'}`), {
      source: "OpenAIHandler.js",
      context: "handleError",
      errorType: data.error?.type,
      errorCode: data.error?.code,
      errorDetails: data.error
    });
  }

  // ==========================================
  // UTILITAIRES
  // ==========================================

  /**
   * R√©cup√®re la transcription compl√®te
   * @returns {string} Transcription de l'appel
   */
  getTranscription() {
    return this.transcription;
  }
}

